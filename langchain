from langchain.document_loaders.csv_loader import CSVLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import VertexAIEmbeddings#deprecated
from langchain_google_vertexai import VertexAIEmbeddings#updated
from langchain.vectorstores import Pinecone
from langchain.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
import sys
import pandas as pd
a=pd.read_csv('transc_sum_v1.csv')
a.head(2)
loader=CSVLoader(file_path='only_trans.csv',encoding='utf-8',csv_args={'delimiter':','})
data=loader.load()
Request_per_min=560
embeddings=VertexAIEmbeddings(requests_per_minute=Request_per_min)
DB_FAISS='VectorStore/db_faiss_3'
docsearch=FAISS.from_documents(text_chunks,embeddings)
docsearch.save_local(DB_FAISS)
from langchain.llms import VertexAI
llm=VertexAI(model_name='text-bison-32k',maximum_output_tokens=8000,tempearature=0.2,top_p=0.8,top_k=40,verbose=True)
import sys
qa = ConversationalRetrievalChain.from_llm(llm, retriever=docsearch.as_retriever())
while True:
  chat_history = []
  query = input(f"Input Prompt: ")
  if query == 'exit':
    print('Exiting')
    sys.exit()
  if query == '':
    continue
  result = qa({"question":query, "chat_history":chat_history})
  print("Response: ", result['answer'])
This is my code execution has no problem but the problem  is the output. Ill show it below
Input Prompt:  Generated top 10 recurring issues discussed in the calls and the count and also give me the fixes given on the that call if not means give not solved
Response:   **Top 10 Recurring Issues:**
1. **ONT/ONU not linking/registering with OLT (12 instances):**
   - **Fixes:**
     - Verify LCP and ensure it's in the right place.
     - Swap the ONT.
     - Check for outages and add a note to the outage ticket if necessary.
2. **No internet connectivity/No ping (5 instances):**
   - **Fixes:**
     - Reset the ONT and DPU.
     - Check operational state and ensure it's not down.
     - Create a
See the output is not fully completed the llm has working good it has potential problem is in retrieval chain



RUN_DT = []
primary_order_item = []
ECO_SOURCE = []
Product_Category = []
net_mrr = []
order_status = []
CUST_ORDER_NBR = []
SERV_ORDER_NBR  = []
SOU  = []
SERVICE_ID = []
TASK_NAME = []
TASK_STATUS = []
START_DATE = []
END_DATE = []
CUST_ORDER_SOURCE = []
DW_SOURCE_SYSTEM = []
MODIFIED_DT = []
PRODUCT_NAME = []
SERV_ORDER_TYP = []
SERV_ORDER_ACTION_TYP = []
SERV_ORDER_STATUS = []
CUST_COMMIT_DT = []
PRODUCT = []
CUST_REQST_DT = []
TASK_CREATE_DT = []
A_COUNTRY_NAME = []
Z_COUNTRY_NAME = []
TASK_DUE_DT = []
IS_NEW_VERSION = []
SM_VERSION = []
# M_VERSION = []
IS_FALLOUT_TASK = []
ONNET=[]
total_tasks = []
total_products = []
"Total_Tasks","total_products","total_fallouts",
ONNET_COUNT=[]
for order_id in df['primary_order_item'].unique():
    sub_df = df[df['primary_order_item'] == order_id]
    sub_df = sub_df.sort_values(by="START_DATE",ascending=True)
    total_tasks.append(len(sub_df))
    total_products.append(sub_df['PRODUCT_NAME'].nunique())
    RUN_DT.append(sub_df['RUN_DT'].iloc[0])
    primary_order_item.append(sub_df['primary_order_item'].iloc[0])
    ECO_SOURCE.append(sub_df['ECO_SOURCE'].iloc[0])
    Product_Category.append(sub_df['Product_Category'].iloc[0])
    net_mrr.append(sub_df['net_mrr'].iloc[0])
    order_status.append(sub_df['order_status'].iloc[0])
    CUST_ORDER_NBR.append(sub_df['CUST_ORDER_NBR'].iloc[0])
    SERV_ORDER_NBR.append(sub_df['SERV_ORDER_NBR'].iloc[0]) 
    SOU.append(sub_df['SOU'].iloc[0])
    SERVICE_ID.append(sub_df['SERVICE_ID'].iloc[0])
    TASK_NAME.append(len(sub_df['TASK_NAME'].unique()))
    try:
        TASK_STATUS.append((dict(sub_df['TASK_STATUS'].value_counts())['Completed']/len(sub_df))*100)
    except:
        TASK_STATUS.append(0)
    START_DATE.append(sub_df['START_DATE'].iloc[0])
    END_DATE.append(sub_df['END_DATE'].iloc[0])
    CUST_ORDER_SOURCE.append(sub_df['CUST_ORDER_SOURCE'].iloc[0])
    DW_SOURCE_SYSTEM.append(sub_df['DW_SOURCE_SYSTEM'].iloc[0])
    MODIFIED_DT.append(sub_df['MODIFIED_DT'].iloc[0])
    prd = ','.join(sub_df['PRODUCT_NAME'].dropna().unique())
    PRODUCT_NAME.append(prd)
    
    SERV_ORDER_TYP.append(sub_df['SERV_ORDER_TYP'].iloc[0])
    SERV_ORDER_ACTION_TYP.append(sub_df['SERV_ORDER_ACTION_TYP'].iloc[0])
    SERV_ORDER_STATUS.append(sub_df['SERV_ORDER_STATUS'].iloc[0])
    CUST_COMMIT_DT.append(sub_df['CUST_COMMIT_DT'].iloc[0])
    PRODUCT.append(sub_df['PRODUCT'].iloc[0])
    CUST_REQST_DT.append(sub_df['CUST_REQST_DT'].iloc[0])
    TASK_CREATE_DT.append(sub_df['TASK_CREATE_DT'].iloc[0])
    A_COUNTRY_NAME.append(sub_df['A_COUNTRY_NAME'].iloc[0])
    Z_COUNTRY_NAME.append(sub_df['Z_COUNTRY_NAME'].iloc[0])
    TASK_DUE_DT.append(sub_df['TASK_DUE_DT'].iloc[-1])
    IS_NEW_VERSION.append(sub_df['IS_NEW_VERSION'].iloc[0])
    SM_VERSION.append(sub_df['SM_VERSION'].iloc[0])
    ONNET.append(sub_df['onnet'].iloc[0])
    ONNET_COUNT.append(sub_df['onnet_count'].iloc[0])
    # M_VERSION.append(sub_df['M_VERSION'].iloc[0])
    try:
        IS_FALLOUT_TASK.append((sub_df['IS_FALLOUT_TASK'].value_counts()[1]/len(sub_df))*100)
    except KeyError:
        IS_FALLOUT_TASK.append(0)

new_df = pd.DataFrame({"RUN_DT":RUN_DT,
"primary_order_item":primary_order_item,
'ECO_SOURCE':ECO_SOURCE,
'Product_Category':Product_Category,
'net_mrr':net_mrr,
'order_status':order_status,
'CUST_ORDER_NBR':CUST_ORDER_NBR,
'SERV_ORDER_NBR':SERV_ORDER_NBR ,
'SOU':SOU, 
'SERVICE_ID':SERVICE_ID,
'TASK_NAME':TASK_NAME,
'TASK_STATUS':TASK_STATUS,
'START_DATE':START_DATE,
'END_DATE':END_DATE,
'CUST_ORDER_SOURCE':CUST_ORDER_SOURCE,
'DW_SOURCE_SYSTEM':DW_SOURCE_SYSTEM,
'MODIFIED_DT':MODIFIED_DT,
'PRODUCT_NAME':PRODUCT_NAME,
'SERV_ORDER_TYP':SERV_ORDER_TYP,
'SERV_ORDER_ACTION_TYP':SERV_ORDER_ACTION_TYP,
'SERV_ORDER_STATUS':SERV_ORDER_STATUS,
'CUST_COMMIT_DT':CUST_COMMIT_DT,
'PRODUCT':PRODUCT,
'CUST_REQST_DT':CUST_REQST_DT,
'TASK_CREATE_DT':TASK_CREATE_DT,
'A_COUNTRY_NAME':A_COUNTRY_NAME,
'Z_COUNTRY_NAME':Z_COUNTRY_NAME,
'TASK_DUE_DT':TASK_DUE_DT,
'IS_NEW_VERSION':IS_NEW_VERSION,
'SM_VERSION':SM_VERSION,
# 'M_VERSION':M_VERSION,
'onnet':ONNET,
'onnet_count':ONNET_COUNT,
'total_fallouts':IS_FALLOUT_TASK,
"total_tasks":total_tasks,
"total_products":total_products})




import pandas as pd

# Grouping by 'primary_order_item' and aggregating values
grouped = df.groupby('primary_order_item').agg({
    'RUN_DT': 'first',
    'ECO_SOURCE': 'first',
    'Product_Category': 'first',
    'net_mrr': 'first',
    'order_status': 'first',
    'CUST_ORDER_NBR': 'first',
    'SERV_ORDER_NBR': 'first',
    'SOU': 'first',
    'SERVICE_ID': 'first',
    'TASK_NAME': lambda x: x.nunique(),
    'TASK_STATUS': lambda x: (x.eq('Completed').sum() / len(x)) * 100 if len(x) > 0 else 0,
    'START_DATE': 'first',
    'END_DATE': 'first',
    'CUST_ORDER_SOURCE': 'first',
    'DW_SOURCE_SYSTEM': 'first',
    'MODIFIED_DT': 'first',
    'PRODUCT_NAME': lambda x: ','.join(x.dropna().unique()),
    'SERV_ORDER_TYP': 'first',
    'SERV_ORDER_ACTION_TYP': 'first',
    'SERV_ORDER_STATUS': 'first',
    'CUST_COMMIT_DT': 'first',
    'PRODUCT': 'first',
    'CUST_REQST_DT': 'first',
    'TASK_CREATE_DT': 'first',
    'A_COUNTRY_NAME': 'first',
    'Z_COUNTRY_NAME': 'first',
    'TASK_DUE_DT': 'last',
    'IS_NEW_VERSION': 'first',
    'SM_VERSION': 'first',
    'onnet': 'first',
    'onnet_count': 'first',
    'IS_FALLOUT_TASK': lambda x: (x.sum() / len(x)) * 100 if len(x) > 0 else 0,
    'total_tasks': 'size',
    'total_products': lambda x: x.nunique()
})

# Creating the new DataFrame
new_df = grouped.reset_index()




z = []
for i in df_6['WM_TASK_ID'].unique():
    if i in merged_df['WM_TASK_ID'].unique():
        z.append(i)
        print(i)
    else:
        pass
    
print(len(z))



# Convert unique values to sets
df6_unique_ids = set(df_6['WM_TASK_ID'].unique())
merged_unique_ids = set(merged_df['WM_TASK_ID'].unique())

# Find the intersection of unique values
z = df6_unique_ids.intersection(merged_unique_ids)

# Print the common values
for i in z:
    print(i)

print(len(z))




TOTAL_TASKS = []
TOTAL_PRODUCTS = []
TOTAL_MILESTONES = []
TOTAL_FALLOUTS = []
TASK_COMPLETION = []
for i in final_df['PRIMARY_ORDER_ITEM'].unique():
    sdf = final_df[final_df['PRIMARY_ORDER_ITEM'] == i]
    for j in sdf['PRODUCT_NAME']:
        v = sdf[sdf['PRODUCT_NAME'] == j ]
        TOTAL_FALLOUTS.append(sdf['IS_FALLOUT_TASK'].sum())
        TOTAL_PRODUCTS.append(v['PRODUCT_NAME'].count())
        TOTAL_TASKS.append(v['TASK_NAME'].count())
        TOTAL_MILESTONES.append(v['TASK MILESTONE'].count())
        tc = sum(k in ['I_COMPLETED', 'Completed ', 'Complete', 'COMPLETE'] for k in sdf['TASK_STATUS'] )
        TASK_COMPLETION.extend([tc] * len(sdf))


import pandas as pd
import numpy as np

# Assuming you have a DataFrame named 'data' with your dataset
# Replace 'dependent_variable' with the name of your dependent variable
dependent_variable = 'target_variable'

# List of columns where NaN values are considered important
important_nan_columns = ['column1', 'column2']

# Impute NaN values with a placeholder value (e.g., -999) for those columns
data_imputed = data.copy()
data_imputed[important_nan_columns] = data_imputed[important_nan_columns].fillna(-999)

# Compute the correlation matrix
correlation_matrix = data_imputed.corr()

# Get correlation of dependent variable with all other variables
correlation_with_dependent = correlation_matrix[dependent_variable]

# Threshold for correlation strength
threshold = 0.5  # Adjust as needed

# Filter variables highly correlated with the dependent variable
significant_correlation = correlation_with_dependent[abs(correlation_with_dependent) > threshold]

# Extract variable names with significant correlation
independent_variables = significant_correlation.index.tolist()
independent_variables.remove(dependent_variable)

# Split data into independent and dependent variables
X = data_imputed[independent_variables]  # Independent variables
y = data_imputed[dependent_variable]     # Dependent variable


 'BLOCK_TYPE', 'CATEGORY', 'REASON', 'HOLD_TIME',
       'DESCRIPTION', 'BLK_SEQ', 'BLK_CREATED_DTTM', 'BLK_MODIFIED_DTTM'

# Step 1: Calculate total number of tasks and order duration
df['Total Tasks'] = df['TOTAL TASKS']
df['Order Duration'] = (df['END DATE'] - df['START DATE']).dt.days

# Step 2: Normalize values
df['Normalized_Total_Tasks'] = (df['Total Tasks'] - df['Total Tasks'].min()) / (df['Total Tasks'].max() - df['Total Tasks'].min())
df['Normalized_Order_Duration'] = (df['Order Duration'] - df['Order Duration'].min()) / (df['Order Duration'].max() - df['Order Duration'].min())

# Step 3: Combine factors
weight_total_tasks = 0.5  # Weight for total tasks
weight_order_duration = 0.5  # Weight for order duration
df['Order_Activity_Intensity'] = (weight_total_tasks * df['Normalized_Total_Tasks']) + (weight_order_duration * df['Normalized_Order_Duration'])

# Step 4: Add the "Order Activity Intensity" column to the dataframe
# Optionally, you can drop the intermediate columns used for calculation
df.drop(['Total Tasks', 'Order Duration', 'Normalized_Total_Tasks', 'Normalized_Order_Duration'], axis=1, inplace=True)



training accuracy - 0.9924878094079754
test accuracy - 0.9689728041002216
mean squared error - 17.113885627530365
mean abosolute error - 1.6384412955465586
r square - 0.9629688787975816

training accuracy - 0.9776850685327265
test accuracy - 0.9768431179975037
mean squared error - 12.77280200766607
mean abosolute error - 1.1235911333529172
r square - 0.9690718871956321

training accuracy - 0.9855197375223229
test accuracy - 0.9636193595773416
mean squared error - 20.06672215113483
mean abosolute error - 1.88195645644342
r square - 0.9588830154515672



df_2.head(2)
x = df_2.drop(["O_NO_OF_DAYS_TAKEN"],axis=1)
y= df_2['O_NO_OF_DAYS_TAKEN']
x['PRODUCT_NAME']=LabelEncoder().fit_transform(x['PRODUCT_NAME'])


x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,shuffle = True)

from sklearn.linear_model import Ridge, Lasso
model_reg = Lasso(alpha=0.1).fit(x_train,y_train)
pred = model_reg.predict(x_test)
print(f"training accuracy - {model_reg.score(x_train,y_train)}")
print(f"test accuracy - {model_reg.score(x_test,y_test)}")
print(f"mean squared error - {mean_squared_error(pred,y_test)}")
print(f"mean abosolute error - {mean_absolute_error(pred,y_test)}")
print(f"r square - {r2_score(pred,y_test)}")
plt.xlabel("predicted")
plt.ylabel("actual")
plt.title("actual vs predicted")
sns.scatterplot(x=pred,y=y_test)

training accuracy - 0.8271040020605858

from sklearn.linear_model import Ridge, Lasso
model_reg_2 = joblib.load('/Workspace/Users/vibhish.ravikumar@lumen.com/time_pred_model.pkl')
pred = model_reg_2.predict(x_test)
print(f"test accuracy - {model_reg_2.score(x_test,y_test)}")
print(f"mean squared error - {mean_squared_error(pred,y_test)}")
print(f"mean abosolute error - {mean_absolute_error(pred,y_test)}")
print(f"r square - {r2_score(pred,y_test)}")
plt.xlabel("predicted")
plt.ylabel("actual")
plt.title("actual vs predicted")
sns.scatterplot(x=pred,y=y_test)
test accuracy - 0.7994369566481376
mean squared error - 280.1247967749637
mean abosolute error - 12.954296266700855
r square - 0.7380866983778717
